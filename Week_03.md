# Week 3: Big Data and the (Expert) State

## Discussion Prompts

Many scholars argue that government use of big data and machine learning poses dangers to society. What policies could be implemented to ensure that emerging technologies are used for good?

* What is good? 
* Use non-digital data for checks and balances.
* Data rights akin to property rights.
* Security policies. 
* You can't use technology if you can't explain how it works.
* Establishing best practices: FAIR datasets that could be used as benchmarks, etc.
* A national AI assistant, comparable to Alexa/Siri etc. that would assist people with public services (presumably by storing data related to them)
* Several monitoring instances
* Opt-in/opt-out options
* Aspire to develop causal models (invest in research!)
* Fix framwork, how to approach, record/report analysis
* Governmental Review Board for all government studies (internal or conducted by consultants) that use government collected data for study.
* Wholeness and reliability of data particularly if it is purchased
* Democracy + journalism + upskilled civil servants/MPs - good institutions should hopefully produce the right kind of policies. I can't come up with good policies in an armchair.
* Regulations on function creep (e.g. require explicit consent each time data is used for a new purpose)
* Study how the implementation may affect the data itself
* Transparency: government should publish algorithms, data, assumptions etc. being used and have a way to be challenged by both other experts and the person affected by this (e.g. right to explanation)
* Right to challenge algorithmic output in addition to right to explanation (?)
* Linked to transparency & accountability: government should promote an open data approach and help citizens/journalists to acquire necessary skills to control governmental actions
* Enable freedom of information requests to be made to ascertain what data and/or algorithms have been used in specific policymaking applications 
* IRB/CUREC for government (present assessment of potential harms, analysis of bias in datasets, e.g. sexism in word embeddings)
* Ensure that contracts between governmental organizations and private companies are made public and subject to regular review (e.g. NOPD/Palantir contract: https://www.theverge.com/2018/2/27/17054740/palantir-predictive-policing-tool-new-orleans-nopd)
* Aligned incentives between governments and the people. Questioning the effectiveness of democracy. Allowing non-government organisations to have access to similar data to ensure mutual monitoring across institutions.

## Formative Assignments

Consider the (in?)famous [Facebook emotional contagion study](http://www.pnas.org/content/111/24/8788). How might one structure a formative based on this study?

### Introduction

Something.

### Epistemological or scientific validity of big data approaches

#### Opportunities
* Large sample sizes mean that you can detect small effect sizes with greater confidence and precision. In other words, this study has high statistical power. 
* Experimenting within a product that is actively used means you can give 'treatments' to users and measure their effects. (A/B testing).
* Opportunity to spot/explore granular effects or causes.
* Trace data can be more reliable than self-reported data.

#### Challenges
* The setup is questionable. Should we scientifically assume that exposing people to neg/pos content would make them post in the same spirit? What about people who don't post much at all? Is that controled for? Too simplistic of a mechanism to show effect on mood.
* We may lack good diagnostic criteria for subjective mood states, i.e. we can't make "scientific" statements about "mood contagion" using these kinds of data.
* Are we measuring the right thing? Does the sentiment contained in what someone posts serve as a good surrogate for how they're feeling.
* Massive sample size (as stated at the very beginning of abstract!) isn't a measure of quality of study.
* External validity to other countries/languages/cultures?
* Statistical tests will give significant results due to large sample size. Are the results useful?
* "Posts were determined to be positive or negative if they contained at least one positive or negative word, as defined by Linguistic Inquiry and Word Count software"--is this the most nuanced sentiment analysis technique they could have used?
* Small effect on individual level. Does it scale? 
"Given the massive scale of social networks such as Facebook, even small effects can have large aggregated consequences. After all, an effect size of d = 0.001 at Facebookâ€™s scale is not negligible: In early 2013, this would have corresponded to hundreds of thousands of emotion expressions in status updates per day."
* Selection bias

### Ethical and social aspects or implications of research

#### Opportunities
* Challenging the ethics of Facebook's existing practices of customizing newsfeeds.
* Data has already been taken and the user signed an agreement for it. Academic use is fair under that agreement.
* Discovering new social or pychological effects of emotions on the web.
* The ability to influence peoples' moods is a great opportunity if we want to devise strategies to increase a society's "happiness" index.
* The ability to understand how online networks affect our moods.
* Opportunity to do research with big sample size and ecological validity at low cost.

#### Challenges
* Ethical issues with consent; did the users agree to participate in this study?
* Potential for harm against population being experimented on.
* There may be serious consequences for peoples' mental health if they are led to believe that their emotions and thoughts are highly or totally outside of their control
* Political context - this research absolutely caught fire in the media, which has affected the way it's been interpreted
* Context: was there actually a "greater good" realisable from the experiment that would justify it despite participants' non-consent?


### Practical implications and limits

#### Opportunities
* We could maybe set up social media in a way that makes people happier. Why wouldn't we want that?
* If the content we are shown significantly affects our mood, perhaps Facebook could control the number of negative posts we see in a given sitting.
* New regulations/research ethics guidelines requiring consent for each new use of data rather than just initial collection.
* Relate to existing studies on FB such as the echo chamber effect.
* Study social movement theory, to see how many of these emotional contagions have led to mobilization.
* Validating a 'classic theory' in the social sciences in a new and modern platform.

#### Challenges
* The interests of individuals and the interests of corporations seem to have become a bit unaligned - Facebook has an incentive to make an addictive product, not necessarily one that makes us happy.
* How people express themselves online does not always reflect real life emotions.
* How big technology companies take advantage of the 'Data Use Policy' to perform research.


### Conclusion
In this paper, I have summarized the epistemological policy and social implications of Social Data Science, using the case study of the Emotional Contagion study that uses Facebook data with lots of data points.




